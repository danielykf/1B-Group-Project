{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "69bdbc2b0047b565956940a963d4fc84cfcc03ae4c16a47a796ddc58164ce876"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.data import *\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import segmentation_models\n",
    "from segmentation_models.losses import *\n",
    "from segmentation_models.metrics import iou_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from output_processing import output_image_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "source": [
    "# Image Preprocessing & Prepare Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOTDIR = r\"./data\"\n",
    "# Training data should be at DATA_ROOTDIR/train\n",
    "# Testing data should be at DATA_ROOTDIR/test\n",
    "\n",
    "IMAGE_DIM = 128\n",
    "# Input images have resolution [IMAGE_DIM, IMAGE_DIM, 3]\n",
    "# Output masks have resolution [IMAGE_DIM, IMAGE_DIM]\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_SPLIT = 0.8\n",
    "VALIDATION_SPLIT = 1 - TRAIN_SPLIT"
   ]
  },
  {
   "source": [
    "## Calculating the size of training and validation folds"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_data_points(fold):\n",
    "    # fold: \"train\" / \"test\"\n",
    "    rootdir = DATA_ROOTDIR\n",
    "    rootdir = os.path.join(rootdir, fold)\n",
    "    dataset_size = 0\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            if \"labelled\" in file:\n",
    "                dataset_size += 1\n",
    "    return dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train size: 4463\nValidation size: 1116\n"
     ]
    }
   ],
   "source": [
    "train_dataset_size = count_data_points(\"train\")\n",
    "\n",
    "train_size = int(train_dataset_size * TRAIN_SPLIT)\n",
    "validation_size = train_dataset_size - train_size\n",
    "\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Validation size: {validation_size}\")"
   ]
  },
  {
   "source": [
    "## Parsing the image data from DATA_ROOTDIR"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(IMAGE_DIM, IMAGE_DIM),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "def parse_image(mask_path):\n",
    "    mask_png = tf.io.read_file(mask_path)\n",
    "    mask = tf.io.decode_png(mask_png)\n",
    "    mask = tf.image.rgb_to_grayscale(mask)\n",
    "    mask = resize_and_rescale(mask)\n",
    "    mask = 1 - mask\n",
    "\n",
    "    image_path = tf.strings.substr(mask_path, 0, tf.strings.length(mask_path) - tf.strings.length(\"-labelled.png\")) + \".png\"\n",
    "    image_png = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_png(image_png)\n",
    "    image = resize_and_rescale(image)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "source": [
    "## Data Augmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(image, mask):\n",
    "    # Flipping left and right randomly\n",
    "    flip_left_right = tf.math.round(tf.random.uniform([]))\n",
    "    if flip_left_right == 1:\n",
    "        tf.image.flip_left_right(image)\n",
    "        tf.image.flip_left_right(mask)\n",
    "    \n",
    "    # Flipping up and down randomly\n",
    "    flip_up_down = tf.math.round(tf.random.uniform([]))\n",
    "    if flip_up_down == 1:\n",
    "        tf.image.flip_up_down(image)\n",
    "        tf.image.flip_up_down(mask)\n",
    "    \n",
    "    # Rotation by random angle\n",
    "    rot_ang = tf.random.uniform([], minval=0, maxval=np.pi * 2)\n",
    "    image = tfa.image.rotate(image, rot_ang)\n",
    "    mask = tfa.image.rotate(mask, rot_ang)\n",
    "\n",
    "    # Rotation by either [0, 90, 180, 270] degrees\n",
    "    # rot_cnt = tf.cast(tf.math.floor(tf.random.uniform([], minval=0, maxval=4)), dtype=tf.int32)\n",
    "    # image = tf.image.rot90(image, rot_cnt)\n",
    "    # mask = tf.image.rot90(mask, rot_cnt)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "source": [
    "## Configuring the training and validation datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<BatchDataset shapes: ((16, None, None, None), (16, 128, 128, 1)), types: (tf.float32, tf.float32)>\n<BatchDataset shapes: ((16, 128, 128, None), (16, 128, 128, 1)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "def configure_dataset(dataset, training=False):\n",
    "    dataset = dataset.shuffle(1000).repeat().map(parse_image)\n",
    "    if training:\n",
    "        # Only augment the training fold\n",
    "        dataset = dataset.map(lambda image, mask: augment_data(image, mask))\n",
    "    return dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# Load the list of mask paths into train_dataset\n",
    "# Do not shuffle the dataset at this stage - Tiles are overlapping and ordered from top-left to bottom-right, so shuffling might result in significant overlap of areas between training and validation data\n",
    "train_dataset = Dataset.list_files(os.path.join(DATA_ROOTDIR, \"train\", \"*-labelled.png\"), shuffle=False)\n",
    "\n",
    "# Split the entire dataset (of paths) into training and validation folds\n",
    "train_ds = train_dataset.take(train_size)\n",
    "validation_ds = train_dataset.skip(train_size).take(validation_size)\n",
    "\n",
    "# Set up the image dataset from the path dataset\n",
    "train_ds = configure_dataset(train_ds, training=True)\n",
    "validation_ds = configure_dataset(validation_ds)\n",
    "\n",
    "print(train_ds)\n",
    "print(validation_ds)"
   ]
  },
  {
   "source": [
    "# Building the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each model will be stored in a separate folder named by the model itself in the MODELS_ROOTDIR\n",
    "MODELS_ROOTDIR = r\"./\"\n",
    "\n",
    "# if MODEL_LOADED == None: train new model; otherwise, load the specified existing model\n",
    "MODEL_LOADED = \"model @2021-03-09 13-52-58.147135\"\n"
   ]
  },
  {
   "source": [
    "## Model Architecture"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = segmentation_models.Unet(\"resnet34\", encoder_weights=\"imagenet\", decoder_use_batchnorm=True)\n",
    "model.compile('Adam', loss=DiceLoss(0.8), metrics=[iou_score, Precision(0.5), Recall(0.5)])"
   ]
  },
  {
   "source": [
    "## Configure how the Model is saved"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "timestamp = str(datetime.datetime.now())\n",
    "timestamp = timestamp.replace(\":\", \"-\")\n",
    "\n",
    "rootdir = MODELS_ROOTDIR\n",
    "folder = MODEL_LOADED\n",
    "if folder == None:\n",
    "    folder = f\"model @{timestamp}\" # Name of model\n",
    "\n",
    "model_dir = os.path.join(rootdir, folder) # Path of model to be saved\n",
    "checkpoint_path = os.path.join(model_dir, \"weights\") # Path of model weights to be saved"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Train the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a new model only if model_dir does not exist\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "    # Only save the best model (smallest loss) obtained throughout the training process\n",
    "    cp_callback = callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True, monitor=\"val_loss\", verbose=1)\n",
    "\n",
    "    # Save model history?\n",
    "    # Plot history graph with tensorboard?\n",
    "    history = model.fit(x=train_ds, initial_epoch=0, epochs=35, steps_per_epoch=200, validation_data=validation_ds, validation_steps=50, callbacks=[cp_callback], workers=12)"
   ]
  },
  {
   "source": [
    "# Testing the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Configure the test dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test size: 1127\n<BatchDataset shapes: ((16, 128, 128, None), (16, 128, 128, 1)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "test_ds = Dataset.list_files(os.path.join(DATA_ROOTDIR, \"test\", \"*-labelled.png\"), shuffle=False)\n",
    "test_size = count_data_points(\"test\")\n",
    "test_ds = test_ds.map(parse_image).repeat(1).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(f\"Test size: {test_size}\")\n",
    "print(test_ds)"
   ]
  },
  {
   "source": [
    "## Evaluate the Model on the test dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "70/70 [==============================] - 8s 90ms/step - loss: 0.3990 - iou_score: 0.4776 - precision_1: 0.5266 - recall_1: 0.8647\n",
      "{'loss': 0.435035765171051, 'iou_score': 0.4369751811027527, 'precision_1': 0.48186537623405457, 'recall_1': 0.8229793310165405}\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "test_results = model.evaluate(x=test_ds, return_dict=True)\n",
    "print(test_results)"
   ]
  },
  {
   "source": [
    "## Save the predicted masks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dir = os.path.join(model_dir, \"predictions\")\n",
    "if not os.path.isdir(predictions_dir):\n",
    "    os.mkdir(predictions_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "\n",
    "def plot_save(filename, show, *images):\n",
    "    images_count = len(images)\n",
    "    fig, ax = plt.subplots(1, images_count)\n",
    "    for i in range(images_count):\n",
    "        ax[i].imshow(images[i])\n",
    "    np.vectorize(lambda ax: ax.axis(\"off\"))(ax)\n",
    "\n",
    "    if filename != None:\n",
    "        fig.savefig(filename)\n",
    "\n",
    "    if not show:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = test_ds\n",
    "\n",
    "test_count = 0\n",
    "for images, masks in test_batch:\n",
    "    masks_pred = model.predict(images)\n",
    "    for i, mask_pred in enumerate(masks_pred):\n",
    "        image, mask = images[i], masks[i]\n",
    "        mask_smoothed = output_image_processing(mask_pred, 7, 0.5)\n",
    "        test_count += 1\n",
    "        filename = os.path.join(predictions_dir, f\"test_{test_count}\")\n",
    "        plot_save(filename, test_count <= 16, image, mask, mask_pred, mask_smoothed)"
   ]
  }
 ]
}